---
title: 'Data structure'
author: "Jae Yeon Kim"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

# Setup 

- Check your `dplyr` package is up-to-date by typing `packageVersion("dplyr")`. If the current installed version is less than 1.0, then update by typing `update.packages("dplyr")`. You may need to restart R to make it work.

```{r}
ifelse(packageVersion("dplyr") >= 1,
  "The installed version of dplyr package is greater than or equal to 1.0.0", update.packages("dplyr")
)

if (!require("pacman")) install.packages("pacman")

pacman::p_load(
  tidyverse, # the tidyverse framework
  here, # computational reproducibility
  gapminder, # toy data
  nycflights13, # for exercise
  ggthemes, # additional themes
  ggrepel, # annotating ggplot with text 
  patchwork, # arranging ggplots
  broom # tidying model outputs
)
```

# Tidying (tidyr)

## Reshaping

**Signs of messy datasets**

* 1. Column headers are values, not variable names.
* 2. Multiple variables are not stored in one column.
* 3. Variables are stored in both rows and columns.
* 4. Multiple types of observational units are stored in the same table.
* 5. A single observational unit is stored in multiple tables.

Let's take a look at the cases of untidy data.

![Messy Data Case 1 (Source: R for Data Science)](https://garrettgman.github.io/images/tidy-5.png)

-   Make It Longer

    | Col1 | Col2 | Col3 |
    |------|------|------|
    |      |      |      |
    |      |      |      |
    |      |      |      |

**Challenge**: Why is this data not tidy?

```{r}
table4a
```

-   Let's pivot (rotate by 90 degrees).


![Concept map for pivoting. By Florian Schmoll, Monica Alonso.](https://github.com/rstudio/concept-maps/raw/master/en/pivoting.svg)


-   [`pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) increases the number of rows (longer) and decreases the number of columns. The inverse function is `pivot_wider()`. These functions improve the usability of `gather()` and `spread()`.

![What pivot\_longer() does (Source: <https://www.storybench.org>)](https://www.storybench.org/wp-content/uploads/2019/08/pivot-longer-image.png)


![Concept map for pipe operator. By Jeroen Janssens, Monica Alonso.](https://education.rstudio.com/blog/2020/09/concept-maps/pipe-operator.png)

- The pipe operator `%>%` originally comes from the `magrittr` package. The idea behind the pipe operator is [similar to](https://www.datacamp.com/community/tutorials/pipe-r-tutorial) what we learned about chaining functions in high school. f: B -> C and g: A -> B can be expressed as $f(g(x))$. The pipe operator chains operations. When you read pipe operator, read as "and then" (Wickham's recommendation). The keyboard shortcut is ctrl + shift + M. The key idea here is not creating temporary variables and focusing on verbs (functions). We'll learn more about this functional programming paradigm later on.

```{r}
table4a 
# Old way, less intuitive
table4a %>%
  gather(
    key = "year", # Current column names
    value = "cases", # The values matched to cases
    c("1999", "2000")
  ) # Selected columns
```

```{r}
# New way, more intuitive
table4a %>%
  pivot_longer(
    cols = c("1999", "2000"), # Selected columns
    names_to = "year", # Shorter columns (the columns going to be in one column called year)
    values_to = "cases"
  ) # Longer rows (the values are going to be in a separate column called named cases)
```

-   There's another problem, did you catch it?

-   The data type of `year` variable should be `numeric` not `character`. By default, `pivot_longer()` transforms uninformative columns to character.

-   You can fix this problem by using `names_transform` argument.

```{r}
table4a %>%
  pivot_longer(
    cols = c("1999", "2000"), # Put two columns together
    names_to = "year", # Shorter columns (the columns going to be in one column called year)
    values_to = "cases", # Longer rows (the values are going to be in a separate column called named cases)
    names_transform = list(year = readr::parse_number)
  ) # Transform the variable
```

**Additional tips**

`parse_number()` also keeps only numeric information in a variable.

```{r}
parse_number("reply1994")
```

A flat file (e.g., CSV) is a rectangular shaped combination of strings. [Parsing](https://cran.r-project.org/web/packages/readr/vignettes/readr.html) determines the type of each column and turns into a vector of a more specific type. Tidyverse has `parse_` functions (from `readr` package) that are flexible and fast (e.g., `parse_integer()`, `parse_double()`, `parse_logical()`, `parse_datetime()`, `parse_date()`, `parse_time()`, `parse_factor()`, etc).

-   Let's do another practice.

**Challenge**

1.  Why is this data not tidy? (This exercise comes from [`pivot` function vigenette](https://tidyr.tidyverse.org/articles/pivot.html).) Too long or too wide?

```{r}
billboard
```

2.  How can you fix it? Which pivot?

```{r}
# Old way
billboard %>%
  gather(
    key = "week",
    value = "rank",
    starts_with("wk")
  ) %>% # Use regular expressions
  drop_na() # Drop NAs
```

-   Note that `pivot_longer()` is more versatile than `gather()`.

```{r}
# New way
billboard %>%
  pivot_longer(
    cols = starts_with("wk"), # Use regular expressions
    names_to = "week",
    values_to = "rank",
    values_drop_na = TRUE # Drop NAs
  )
```

-   Make It Wider

-   Why is this data not tidy?

```{r}
table2
```

-   Each observation is spread across two rows.

-   How can you fix it?: `pivot_wider()`.

**Two differences between `pivot_longer()` and `pivot_wider()`**

-   In `pivot_longer()`, the arguments are named `names_to` and `values_to` (*to*).

-   In `pivot_wider()`, this pattern is opposite. The arguments are named `names_from` and `values_from` (*from*).

-   The number of required arguments for `pivot_longer()` is 3 (col, names\_to, values\_to).

-   The number of required arguments for `pivot_wider()` is 2 (names\_from, values\_from).

![What pivot\_wider() does (Source: <https://www.storybench.org>)](https://www.storybench.org/wp-content/uploads/2019/08/pivot-wider-image.png)

```{r}
# Old way
table2 %>%
  spread(
    key = type,
    value = count
  )
```

```{r}
# New way
table2 %>%
  pivot_wider(
    names_from = type, # first
    values_from = count # second
  )
```

Sometimes, a consultee came to me and asked: "I don't have missing values in my original dataframe. Then R said that I have missing values after I've done some data transformations. What happened?"

Here's an answer.

R defines missing values in two ways.

-   *Implicit missing values*: simply not present in the data.

-   *Explicit missing values*: flagged with NA

**Challenge**

The example comes from [*R for Data Science*](https://r4ds.had.co.nz/tidy-data.html).

```{r}
stocks <- tibble(
  year = c(2019, 2019, 2019, 2020, 2020, 2020),
  qtr = c(1, 2, 3, 2, 3, 4),
  return = c(1, 2, 3, NA, 2, 3)
)
stocks
```

-   Where is the explicit missing value?

-   Does `stocks` have implicit missing values?

```{r}
# implicit missing values become explicit
stocks %>%
  pivot_wider(
    names_from = year,
    values_from = return
  )
```

**Challenge**

-   This exercise comes from [`pivot` function vigenette](https://tidyr.tidyverse.org/articles/pivot.html).

-   Could you make `station` a series of dummy variables using `pivot_wider()`?

```{r}
fish_encounters
```

1.  Which pivot should you use?

2.  Are there explicit missing values?

3.  How could you turn these NAs into 0s? Check `values_fill` argument in the `pivot_wider()` function.

-   Separate

![Messy Data Case 2 (Source: R for Data Science)](https://garrettgman.github.io/images/tidy-6.png)

```{r}
# Toy example
df <- data.frame(x = c(NA, "Dad.apple", "Mom.orange", "Daughter.banana"))
df
```

```{r}
# Separate
df %>%
  separate(x, into = c("Name", "Preferred_fruit"))
# Don't need the first variable
df %>%
  separate(x, into = c(NA, "Preferred_fruit"))
```

**Practice**

```{r}
table3
```

-   Note `sep` argument. You can specify how to separate joined values.

```{r}
table3 %>%
  separate(rate,
    into = c("cases", "population"),
    sep = "/"
  )
```

-   Note `convert` argument. You can specify whether automatically convert the new values or not.

```{r}
table3 %>%
  separate(rate,
    into = c("cases", "population"),
    sep = "/",
    convert = TRUE
  ) # cases and population become integers
```

-   Unite

`pivot_longer()` \<-\> `pivot_wider()`

`separate()` \<-\> `unite()`

```{r}
# Create a toy example
df <- data.frame(
  name = c("Jae", "Sun", "Jane", NA),
  birthmonth = c("April", "April", "June", NA)
)
# Include missing values
df %>% unite(
  "contact",
  c("name", "birthmonth")
)
# Do not include missing values
df %>% unite("contact",
  c("name", "birthmonth"),
  na.rm = TRUE
)
```

## Filling

This is a relatively less-known function of the tidyr package. I found this function super useful to complete time-series data. For instance, how can you replace NA in the following example (this use case is drawn from the [tidyr package vignette](https://tidyr.tidyverse.org/reference/fill.html).)?

```{r}
# Example 
stock <- tibble::tribble(
  ~ quarter, ~ year, ~stock_price, 
  "Q1", 2000, 10000, 
  "Q2", NA, 10001, # Replace NA with 2000  
  "Q3", NA, 10002, # Replace NA with 2000 
  "Q4", NA, 10003, # Replace NA with 2000 
  "Q1", 2001, 10004, 
  "Q2", NA, 10005, # Replace NA with 2001 
  "Q3", NA, 10006, # Replace NA with 2001 
  "Q4", NA, 10007, # Replace NA with 2001
)
fill(stock, year)
```

Let's take a slightly more complex example. 

```{r}
# Example 
yelp_rate <- tibble::tribble(
  ~ neighborhood, ~restraurant_type, ~popularity_rate, 
  "N1", "Chinese", 5, 
  "N2", NA, 4,   
  "N3", NA, 3,  
  "N4", NA, 2,  
  "N1", "Indian", 1, 
  "N2", NA, 2,  
  "N3", NA, 3,  
  "N4", NA, 4, 
  "N1", "Mexican", 5
)
fill(yelp_rate, restraurant_type) # default is direction = .down 
fill(yelp_rate, restraurant_type, .direction = "up") 
```

# Manipulating (dplyr)


![Concept map for dplyr. By Monica Alonso, Greg Wilson.](https://education.rstudio.com/blog/2020/09/concept-maps/dplyr.png)

`dplyr` is better than the base R approaches to data processing:

- fast to run (due to the C++ backed) and intuitive to type
- works well with tidy data and databases (thanks to [`dbplyr`](https://dbplyr.tidyverse.org/))

## Rearranging

-   Arrange

-   Order rows

```{r}
dplyr::arrange(mtcars, mpg) # Low to High (default)
dplyr::arrange(mtcars, desc(mpg)) # High to Row
```

-   Rename

-   Rename columns

```{r}
df <- tibble(y = c(2011, 2012, 2013))
df %>%
  rename(
    Year = # NEW name
    y
  ) # OLD name
```

## Subset observations (rows)

-   Choose row by logical condition

-   Single condition

```{r}
starwars %>%
  filter(gender == "feminine") %>%
  arrange(desc(height))
```

The following filtering example was inspired by [the suzanbert's dplyr blog post](https://suzan.rbind.io/2018/02/dplyr-tutorial-3/).

-   Multiple conditions (numeric)

```{r}
# First example
starwars %>%
  filter(height < 180, height > 160) %>%
  nrow()
# Same as above
starwars %>%
  filter(height < 180 & height > 160) %>%
  nrow()
# Not same as above
starwars %>%
  filter(height < 180 | height > 160) %>%
  nrow()
```

**Challenge**

(1) Use `filter(between())` to find characters whose heights are between 180 and 160 and (2) count the number of these observations.

-   Minimum reproducible example

```{r}
df <- tibble(
  heights = c(160:180),
  char = rep("none", length(c(160:180)))
)
df %>%
  filter(between(heights, 161, 179))
```

-   Multiple conditions (character)

```{r}
# Filter names include ars; `grepl` is a base R function
starwars %>%
  filter(grepl("ars", tolower(name)))
# Or, if you prefer dplyr way
starwars %>%
  filter(str_detect(tolower(name), "ars"))
# Filter brown and black hair_color
starwars %>%
  filter(hair_color %in% c("black", "brown"))
```

**Challenge**

Use `str_detect()` to find characters whose names include "Han".

-   Choose row by position (row index)

```{r}
starwars %>%
  arrange(desc(height)) %>%
  slice(1:6)
```

-   Sample by a fraction

```{r}
# For reproducibility
set.seed(1234)
# Old way
starwars %>%
  sample_frac(0.10,
    replace = FALSE
  ) # Without replacement
# New way
starwars %>%
  slice_sample(
    prop = 0.10,
    replace = FALSE
  )
```

-   Sample by number

```{r}
# Old way
starwars %>%
  sample_n(20,
    replace = FALSE
  ) # Without replacement
# New way
starwars %>%
  slice_sample(
    n = 20,
    replace = FALSE
  ) # Without replacement
```

-   Top 10 rows orderd by height

```{r}
# Old way
starwars %>%
  top_n(10, height)
# New way
starwars %>%
  slice_max(height, n = 10) # Variable first, Argument second
```

## Subset variables (columns)

```{r}
names(msleep)
```

-   Select only numeric columns

```{r}
# Only numeric
msleep %>%
  dplyr::select(where(is.numeric))
```

**Challenge**

Use `select(where())` to find only non-numeric columns

-   Select the columns that include "sleep" in their names

```{r}
msleep %>%
  dplyr::select(contains("sleep"))
```

-   Select the columns that include either "sleep" or "wt" in their names

-   Basic R way

`grepl` is one of the R base pattern matching functions.

```{r}
msleep[grepl("sleep|wt", names(msleep))]
```

**Challenge**

Use `select(match())` to find columns whose names include either "sleep" or "wt".

-   Select the columns that start with "b"

```{r}
msleep %>%
  dplyr::select(starts_with("b"))
```

-   Select the columns that end with "wt"

```{r}
msleep %>%
  dplyr::select(ends_with("wt"))
```

-   Select the columns using both beginning and end string patterns

The key idea is you can use Boolean operators (`!`, `&`, `|`)to combine different string pattern matching statements.

```{r}
msleep %>%
  dplyr::select(starts_with("b") & ends_with("wt"))
```

-   Select the order and move it before everything

```{r}
# By specifying a column
msleep %>%
  dplyr::select(order, everything())
```

-   Select variables from a character vector.

```{r}
msleep %>%
  dplyr::select(any_of(c("name", "order"))) %>%
  colnames()
```

-   Select the variables named in character + number pattern

```{r}
msleep$week8 <- NA
msleep$week12 <- NA
msleep$week_extra <- 0
msleep %>%
  dplyr::select(num_range("week", c(1:12)))
```

**Additional tips**

`msleep` data has nicely cleaned column names. But real-world data are usually messier. The `janitor` package is useful to fix this kind of problem.

```{r}
messy_df <- tibble::tribble(~"ColNum1", ~"COLNUM2", ~ "COL & NUM3",
                            1, 2, 3)
messy_df
pacman::p_load(janitor)
janitor::clean_names(messy_df) 
```

`janitor::tabyl()` is helpful for doing crosstabulation and a nice alternative to `table()` function. 

```{r}
# Frequency table; The default output class is table 
table(gapminder$country)
# Frequency table (unique value, n, percentage)
janitor::tabyl(gapminder$country)
# If you want to add percentage ... 
gapminder %>%
  tabyl(country) %>%
  adorn_pct_formatting(digits = 0, affix_sign = TRUE)
```


## Create variables 

```{r include=FALSE, eval=FALSE}
mutate(.data, # data.frame 
       ...) # new column 
mutate(mtcars, column0 = 0)
```

## Change values using conditions 

You can think of `case_when()` (multiple conditions) as an extended version of `ifelse()` (binary conditions). 

```{r}
mtcars <- mtcars %>%
  mutate(cyl_dummy = case_when(cyl > median(cyl) ~ "High", # if condition
                               cyl < median(cyl) ~ "Low", # else if condition 
                               TRUE ~ 'Median')) # else condition 
mtcars %>% pull(cyl_dummy)
```

## Change values manually 

```{r}
mtcars %>%
  mutate(cyl_dummy = recode(cyl_dummy, # Target column 
                            "High" = "2", # Old - New
                            "Low" = "0",
                            "Median" = "1")) %>%
  pull(cyl_dummy)
```


## Counting

-   How may countries in each continent?

```{r}
gapminder %>%
  count(continent)
```

-   Let's arrange the result.

```{r}
# Just add a new argument `sort = TRUE`
gapminder %>%
  count(continent, sort = TRUE)
# Same as above; How nice!
gapminder %>%
  count(continent) %>%
  arrange(desc(n))
```

**Challenge**

Count the number of observations per `continent` and `year` and arrange them in descending order.

Let's take a deeper look at how things work under the hood.

-   `tally()` works similar to `nrow()`: Calculate the total number of cases in a dataframe

-   `count` = `group_by()` + `tally()`

```{r}
gapminder %>%
  tally()
```

-   `add_tally()` = `mutate(n = n())`

**Challenge**

What does n in the below example represent?

```{r}
gapminder %>%
  dplyr::select(continent, country) %>%
  add_tally()
```

-   `add_count`

Add count as a column.

```{r}
# Add count as a column
gapminder %>%
  group_by(continent) %>%
  add_count(year)
```

**Challenge**

Do cases 1 and 2 in the below code chunk produce the same outputs? If so, why?

```{r}
# Case 1
gapminder %>%
  group_by(continent, year) %>%
  count()
# Case 2
gapminder %>%
  group_by(continent) %>%
  count(year)
```

`count()` is a simple function, but it is still helpful to learn an essential concept underlying complex data wrangling: split-apply-combine strategy. For more information, read Wickham's article (2011) ["The Split-Apply-Combine Strategy for Data Analysis"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.5667&rep=rep1&type=pdf) published in the *Journal of Statistical Software* (especially pages 7-8). [`plyr`](https://github.com/hadley/plyr) was the package (retired) that demonstrated this idea, which has evolved into two directions: [dplyr](https://dplyr.tidyverse.org/) (for data frames) and [purrr](https://purrr.tidyverse.org/) (for lists)

## Summarizing

### Basic

- Create a summary
- Think of `summarise()` as an extended version of `count()`.

```{r}
gapminder %>%
  group_by(continent) %>%
  summarise(
    n = n(),
    mean_gdp = mean(gdpPercap),
    sd_gdp = sd(gdpPercap)
  )
tablea <- gapminder %>%
  group_by(continent) %>%
  summarise(
    n = n(),
    mean_gdp = mean(gdpPercap),
    sd_gdp = sd(gdpPercap)
  )
```

-   Produce publishable tables

```{r}
pacman::p_load(kableExtra,
               flextable)
# For HTML and LaTeX
tablea %>% kableExtra::kable()
# For HTML and MS Office suite
tablea %>% flextable::flextable()
```

### Scoped summaries

-   Old way

-   `summarise_all()`

```{r}
# Create a wide-shaped data example
wide_gapminder <- gapminder %>%
  filter(continent == "Europe") %>%
  pivot_wider(
    names_from = country,
    values_from = gdpPercap
  )
# Apply summarise_all
wide_gapminder %>%
  dplyr::select(-c(1:4)) %>%
  summarise_all(mean, na.rm = TRUE)
```

-   `summarise_if()`: using a logical condition

```{r}
wide_gapminder %>%
  summarise_if(is.double, mean, na.rm = TRUE)
```

-   `summarise_at()`

-   `vars() = select()`

```{r}
wide_gapminder %>%
  summarise_at(vars(-c(1:4)),
    mean,
    na.rm = TRUE
  )
wide_gapminder %>%
  summarise_at(vars(contains("life")),
    mean,
    na.rm = TRUE
  )
```

**Additional tips**


![Concept map for regular expressions. By Monica Alonso, Greg Wilson.](https://github.com/rstudio/concept-maps/raw/master/en/regular-expressions.svg)


-   New way

-   `summarise()` + `across()`


![Concept map for across. By Emma Vestesson](https://github.com/rstudio/concept-maps/raw/master/en/across.svg)


-   If you find using `summarise_all()`, `summarise_if()` and `summarise_at()` confusing, here's a solution: use `summarise()` with `across()`.

-   `summarise_all()`

```{r}
wide_gapminder %>%
  summarise(across(Albania:`United Kingdom`, mean, na.rm = TRUE))
wide_gapminder %>%
  summarise(across(-c(1:4), mean, na.rm = TRUE))
```

-   `summarise_if()`

```{r}
wide_gapminder %>%
  summarise(across(is.double, mean, na.rm = TRUE))
```

-   `summarise_at()`

```{r}
wide_gapminder %>%
  summarise(across(-c(1:4),
    mean,
    na.rm = TRUE
  ))
wide_gapminder %>%
  summarise(across(contains("life"),
    mean,
    na.rm = TRUE
  ))
wide_gapminder %>%
  summarise(across(contains("A", ignore.case = FALSE)))
```

Note that this workshop does not cover creating and manipulating variables using `mutate()` because many techniques you learned from playing with `summarise()` can be directly applied to `mutate()`.

**Challenge**

1.  Summarize the average GDP of countries whose names starting with the alphabet "A".

2.  Turn the summary dataframe into a publishable table using either `kableExtra` or `flextable` package.

## Grouping

### Grouped summaries

- Calculate the mean of `gdpPercap`.

- Some functions are designed to work together. For instance, the group_by
function defines the strata that you're going to use for summary statistics. Then, use summarise() or summarize() for producing summary statistics.

```{r}
gapminder %>%
  group_by(continent) %>% #
  summarise(mean_gdp = mean(gdpPercap))
```

-   Calculate multiple summary statistics.

```{r}
gapminder %>%
  group_by(continent) %>% #
  summarise(
    mean_gdp = mean(gdpPercap),
    count = n()
  )
```

**Optional**

-   Other summary statistics

1.  Measures of spread: `median(x)`, `sd(x)`, `IQR(x)`, `mad(x)` (the median absolute deviation)

```{r}
# The Interquartile Range = The Difference Between 75t and 25t Percentiles
gapminder %>%
  group_by(continent) %>% #
  summarise(IQR_gdp = IQR(gdpPercap))
```

2.  Measures of rank: `min(x)`, `quantile(x, 0.25)`, `max(x)`

```{r}
gapminder %>%
  group_by(continent) %>% #
  summarise(
    min_gdp = min(gdpPercap),
    max_gdp = max(gdpPercap)
  )
```

3.  Measures of position: `first(x)`, `last(x)`, `nth(x, 2)`

```{r}
gapminder %>%
  group_by(continent) %>%
  summarise(
    first_gdp = first(gdpPercap),
    last_gdp = last(gdpPercap)
  )
gapminder %>%
  group_by(continent) %>%
  arrange(gdpPercap) %>% # Adding arrange
  summarise(
    first_gdp = first(gdpPercap),
    last_gdp = last(gdpPercap)
  )
```

4.  Measures of counts: `n(x)` (all rows), `sum(!is.na(x))` (only non-missing rows) = `n_distinct(x)`

```{r}
gapminder %>%
  group_by(continent) %>%
  summarise(ns = n())
```

5.  Counts and proportions of logical values: `sum(condition about x)` (the number of TRUEs in x), `mean(condition about x)` (the proportion of TRUEs in x)

```{r}
gapminder %>%
  group_by(continent) %>%
  summarise(rich_countries = mean(gdpPercap > 20000))
```

**Additional tips**

Also, check out window functions such as `cumsum()` and `lag()`. Window functions are a variant of aggregate functions that take a vector as input then return a vector of the same length as an output. 

```{r}
vec <- c(1:10)
# Typical aggregate function
sum(vec) # The output length is one
# Window function
cumsum(vec) # The output length is ten
```

## Joining

Relational data = multiple tables of data

![Relational data example](https://d33wubrfki0l68.cloudfront.net/245292d1ea724f6c3fd8a92063dcd7bfb9758d02/5751b/diagrams/relational-nycflights.png)

**Key ideas**

- A **primary key** "uniquely identifies an observation in its table"

```{r}
# Example
planes$tailnum %>% head()
```
Verify primary key

`tailnum` should be unique. 

**Challenge**

What do you expect the outcome?

```{r}
planes %>%
  count(tailnum) %>%
  filter(n > 1)
```
**Optional**

If a dataframe doesn't have a primary key, you can add one called a **surrogate** key.

```{r}
# Toy example
df <- tibble(
  x = c(1:3),
  y = c(4:6)
)
# Add a row_index column
df <- df %>% rowid_to_column("ID")
```

- A **foreign** key "uniquely identifies an observation in another table."

```{r}
flights$tailnum %>% head()
```
For joining, don't be distracted by other details and focus on KEYS!

### Mutating joins

> Add new variables to one data frame from matching observations in another"
Using a simple toy example is great because it is easy to see how things work in that much narrow context.

-   Toy example

```{r}
# Table 1
x <- tibble(
  key = c(1:4),
  val_x = c("x1", "x2", "x3", "x4")
)
# Table 2
y <- tibble(
  key = c(1:5),
  val_y = c("y1", "y2", "y3", "y4", "y5")
)
```

-   Inner Join

`inner_join()` keeps the matched values in both tables. If the left table is a subset of the right table, then `left_join()` is the same as `inner_join()`.

**Challenge**

What is going to be the shared keys?

```{r}
inner_join(x, y)
```

![Mutating joins](https://d33wubrfki0l68.cloudfront.net/aeab386461820b029b7e7606ccff1286f623bae1/ef0d4/diagrams/join-venn.png)

-   Left Join

`left_join()`, `right_join()` and `full_join()` are outer join functions. Unlike `inner_join()`, outer join functions keep observations that appear in at least one of the tables.

`left_join()` keeps only the matched observations in the right table.

```{r}
left_join(x, y)
```

-   Right Join

`right_join()` does the opposite. 

```{r}
right_join(x, y)
```

-   Full Join

`full_join()` keeps the observations from both tables. If they were unmatched, then NAs were recoded in one of the two tables.

```{r}
full_join(x, y)
```

### Filtering joins

> Filter observations from one data frame based on whether they match an observation in the other table.
-   Semi Join

In SQL, this type of query is also called subqueries.

-   Filtering without joining

```{r}
# Create the list of the top 10 destinations
top_dest <- flights %>%
  count(dest, sort = TRUE) %>%
  top_n(10)
# Filter
filtered <- flights %>%
  filter(dest %in% top_dest$dest)
```

-   Using semi join: only keep (INCLUDE) the rows that were matched between the two tables

```{r}
joined <- flights %>%
  semi_join(top_dest)
head(filtered == joined)
```

-   Anti Join

`anti_join()` does the opposite. Exclude the rows that were matched between the two tables. A great technique to filter stopwords when you do computational text analysis.

```{r}
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(tailnum, sort = TRUE)
```

# Modeling (broom)

## Nesting

### nest

The following example comes from [R for Data Science](https://r4ds.had.co.nz/many-models.html) by Garrett Grolemund and Hadley Wickham.

-   How can you run multiple models simultaneously? Using a nested data frame.

```{=html}
<iframe width="560" height="315" src="https://www.youtube.com/embed/rz3_FDVt9eg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p> Hadley Wickham: Managing many models with R </p>
```

-   **Grouped data: each row = an observation**

-   **Nested data: each row = a group**

**Challenge**

In the following example, why did we use `country` and `continent` for nesting variables?

```{r}
nested <- gapminder %>%
  group_by(country, continent) %>%
  nest()
head(nested)
nested$data %>% pluck(1)
```

-   Custom function

```{r}
lm_model <- function(df) {
  lm(lifeExp ~ year, data = df)
}
```

-   Apply function to the nested data

```{r}
# Apply m_model to the nested data
nested <- nested %>%
  mutate(models = map(data, lm_model)) # Add the list object as a new column
head(nested)
```

S3 is part of R's object-oriented systems. If you need further information, check out [this section](http://adv-r.had.co.nz/S3.html) in Hadley's Advanced R.

### unnest

- glance() 

`glance()` function from `broom` package inspects the quality of a statistical model.

**Additional tips**

-   `broom::glance(model)`: for evaluating model quality and/or complexity
-   `broom::tidy(model)`: for extracting each coefficient in the model (the estimates + its variability)
-   `broom::augment(model, data)`: for getting extra values (residuals, and influence statistics). A convenient tool in case if you want to plot fitted values and raw data together. 

![Broom: Converting Statistical Models to Tidy Data Frames by David Robinson](https://www.youtube.com/watch?v=7VGPUBWGv6g&ab_channel=Work-Bench)

```{r}
glanced <- nested %>%
  mutate(glance = map(models, broom::glance))
# Pluck the first item on the list 
glanced$glance %>% pluck(1)
# Pull p.value 
glanced$glance %>% pluck(1) %>% pull(p.value)
```

`unnest()` unpacks the list objects stored in the `glanced` column

```{r}
glanced %>%
  unnest(glance) %>%
  arrange(r.squared) 
glanced %>%
  unnest(glance) %>%
  ggplot(aes(continent, r.squared)) +
  geom_jitter(width = 0.5)
```

- tidy() 

```{r}
nested <- gapminder %>%
  group_by(continent) %>%
  nest()
nested <- nested %>%
  mutate(models = map(data, ~lm(lifeExp ~ year + country, data = .))) 
tidied <- nested %>%
  mutate(tidied = map(models, broom::tidy))
model_out <- tidied %>%
  unnest(tidied) %>%
  mutate(term = str_replace(term, "country", "")) %>%
  select(continent, term, estimate, p.value) %>%
  mutate(p_threshold = ifelse(p.value < 0.05, 1, 0))
model_out %>% filter(p_threshold == 1) %>% pull(term) %>% unique()
model_out %>% filter(p_threshold == 0) %>% pull(term) %>% unique()
```


### Mapping

We tasted a little bit about how `map()` function works. Let's dig into it more in-depth as this family of functions is useful. For more information, see Rebecca Barter's excellent tutorial on the `purrr` package. In her words, this is "the tidyverse's answer to apply functions for iteration". `map()` function can take a vector (of any type), a list, and a dataframe for input.

```{r}
multiply <- function(x) {
  x * x
}
df <- list(
  first_obs = rnorm(7, 1, sd = 1),
  second_obs = rnorm(7, 2, sd = 2)
) # normal distribution
```

**Challenge**

Try `map_df(.x = df, .f = multiply)` and tell me what's the difference between the output you got and what you saw earlier.

If you want to know more about the power and joy of functional programming in R (e.g., `purrr::map()`), then please take ["How to Automate Repeated Things in R"](https://github.com/dlab-berkeley/R-functional-programming) workshop.

# Visualizing (ggplot2)

- The following material is adapted from Kieran Healy's excellent book (2019) on [data visualization](https://socviz.co/) and Hadley Wickham's equally excellent book on [ggplot2](https://ggplot2-book.org/). For more theoretical discussions, I recommend you to read [The Grammar of Graphics](https://link.springer.com/book/10.1007%2F0-387-28695-0) by Leland Wilkinson.

- Why should we care about data visualization? More precisely, why should we learn the grammar of statistical graphics?
- Sometimes, pictures are better tools than words in 1) exploring, 2) understanding, and 3) explaining data.

## Motivation 

[Anscombe](https://en.wikipedia.org/wiki/Frank_Anscombe)'s quarter comprises four datasets, which are so alike in terms of their descriptive statistics but quite different when presented graphically.

```{r}
# Set theme
theme_set(theme_minimal())
```

```{r}
# Data
anscombe
```

```{r}
# Correlation
cor(anscombe)[c(1:4), c(5:8)]
```

```{r}
# gather and select
anscombe_processed <- anscombe %>%
  gather(x_name, x_value, x1:x4) %>%
  gather(y_name, y_value, y1:y4)
# plot
anscombe_processed %>%
  ggplot(aes(x = x_value, y = y_value)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  facet_grid(x_name ~ y_name) +
  theme_bw() +
  labs(
    x = "X values",
    y = "Y values",
    title = "Anscombe's quartet"
  )
```

## The grammar of graphics 

- the grammar of graphics 

    - data
    - aesthetic attributes (color, shape, size)
    - geometric objects (points, lines, bars)
    - stats (summary stats)
    - scales (map values in the data space)
    - coord (data coordinates)
    - facet (facetting specifications)
    
No worries about new terms. We're going to learn them by actually plotting. 

- Workflow: 

    1. Tidy data 
    2. Mapping 
    3. Geom 
    4. Cor_ordinates and scales 
    5. Labels and guides
    6. Themes
    7. Save files 

## mapping and geom

- `aes` (aesthetic mappings or aesthetics) tells which variables (x, y) in your data should be represented by which visual elements (color, shape, size) in the plot.

- `geom_` tells the type of plot you are going to use 

## basic aes (x , y)

```{r}
p <- ggplot(
  data = gapminder,
  mapping = aes(x = gdpPercap, y = lifeExp)
) # ggplot or R in general takes positional arguments too. So, you don't need to name data, mapping each time you use ggplot2.
p
p + geom_point()
p + geom_point() + geom_smooth() # geom_smooth has calculated a smoothed line;
# the shaded area is the standard error for the line
```

## Univariate distribution

- `geom_histogram()`: For the probability distribution of a continuous variable. Bins divide the entire range of values into a series of intervals (see [the Wiki entry](https://en.wikipedia.org/wiki/Histogram)). 
- `geom_density()`: Also for the probability distribution of a continuous variable. It calculates a [kernel density estimate](https://en.wikipedia.org/wiki/Kernel_density_estimation) of the underlying distribution. 

### Histogram 

```{r}
data(midwest) # load midwest dataset
midwest
```

```{r, eval = FALSE}
midwest %>%
  ggplot(aes(x = area)) +
  geom_point() # not working.
```

```{r}
midwest %>%
  ggplot(aes(x = area)) +
  geom_histogram() # stat_bin argument picks up 30 bins (or "bucket") by default.
midwest %>%
  ggplot(aes(x = area)) +
  geom_histogram(bins = 10) # only 10 bins.
ggplot(
  data = subset(midwest, state %in% c("OH", "IN")),
  mapping = aes(x = percollege, fill = state)
) +
  geom_histogram(alpha = 0.7, bins = 20) +
  scale_fill_viridis_d()
```

### Density 

```{r}
midwest %>%
  ggplot(aes(x = area, fill = state, color = state)) +
  geom_density(alpha = 0.3) +
  scale_color_viridis_d() +
  scale_fill_viridis_d()
```

## Advanced aes (size, color)

- There's also `fill` argument (mostly used in `geom_bar()`). Color `aes` affects the appearance of lines and points, fill is for the filled areas of bars, polygons, and in some cases, the interior of a smoother's standard error ribbon.

- The property size/color/fill represents... 

```{r}
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    size = pop
  )
) +
  geom_point()
```

```{r}
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    size = pop,
    color = continent
  )
) +
  geom_point() +
  scale_color_viridis_d()
```

```{r}
# try red instead of "red"
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    size = pop,
    color = "red"
  )
) +
  geom_point()
```

Aesthetics also can be mapped per Geom. 

```{r}
p + geom_point() +
  geom_smooth()
p + geom_point(alpha = 0.3) + # alpha controls transparency
  geom_smooth(color = "red", se = FALSE, size = 2)
p + geom_point(alpha = 0.3) + # alpha controls transparency
  geom_smooth(color = "red", se = FALSE, size = 2, method = "lm")
```

```{r}
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    color = continent
  )
) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  )
ggplot(
  data = gapminder,
  mapping = aes(
    x = gdpPercap, y = lifeExp,
    color = continent,
    fill = continent
  )
) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  ) +
  scale_color_viridis_d() +
  scale_fill_viridis_d()
```

## Co-ordinates and scales 

```{r}
p + geom_point() +
  coord_flip() # coord_type
```

The data is heavily bunched up against the left side. 
```{r}
p + geom_point() # without scaling
p + geom_point() +
  scale_x_log10() # scales the axis of a plot to a log 10 basis
p + geom_point() +
  geom_smooth(method = "lm") +
  scale_x_log10()
```


## Labels and guides 

`scales` package has some useful premade formatting functions. You can either load scales or just grab the function you need from the library using `scales::` 

```{r}
p + geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  scale_x_log10(labels = scales::dollar) +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  )
```

6. Themes
```{r}
p + geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  scale_x_log10(labels = scales::dollar) +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  ) +
  theme_economist()
```

## ggsave 

```{r eval = FALSE}
figure_example <- p + geom_point(alpha = 0.3) +
  geom_smooth(method = "gam", color = "red") +
  scale_x_log10(labels = scales::dollar) +
  labs(
    x = "log GDP",
    y = "Life Expectancy",
    title = "A Gapminder Plot",
    subtitle = "Data points are country-years",
    caption = "Source: Gapminder"
  ) +
  theme_economist()
ggsave(figure_example, here("outputs", "figure_example.png"))
```

## Many plots 

Basic ideas:

- Grouping: tell `ggplot2` about the structure of your data 
- Facetting: break up your data into pieces for a plot 

### Grouping

- Can you guess what's wrong?

```{r}
p <- ggplot(gapminder, aes(x = year, y = gdpPercap))
p + geom_point()
p + geom_line()
```

`geom_line` joins up all the lines for each particular year in the order they appear in the dataset. `ggplot2` does not know the yearly observations in your data are grouped by country. 

Note that you need grouping when the grouping information you need to tell is not built into the mapped variables (like continent).

```{r}
gapminder
```

### Facetting 

Facetting is to make small multiples. 

- `facet_wrap`: based on a single categorical variable like `facet_wrap(~single_categorical_variable)`. Your panels will be laid out in order and then wrapped into a grid.

- `facet_grid`: when you want to cross-classify some data by two categorical variables like `facet_grid(one_cat_variable ~ two_cat_variable)`. 

```{r}
p <- ggplot(gapminder, aes(x = year, y = gdpPercap))
p + geom_line(aes(group = country)) # group by, # The outlier is Kuwait.
p + geom_line(aes(group = country)) + facet_wrap(~continent) # facetting
p + geom_line(aes(group = country), color = "gray70") +
  geom_smooth(size = 1.1, method = "loess", se = FALSE) +
  scale_y_log10(labels = scales::dollar) +
  facet_wrap(~continent, ncol = 5) + # for single categorical variable; for multiple categorical variables use facet_grid()
  labs(
    x = "Year",
    y = "GDP per capita",
    title = "GDP per capita on Five continents"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
p + geom_line(aes(group = country), color = "gray70") +
  geom_smooth(size = 1.1, method = "loess", se = FALSE) +
  scale_y_log10(labels = scales::dollar) +
  facet_grid(~continent) + # for single categorical variable; for multiple categorical variables use facet_grid()
  labs(
    x = "Year",
    y = "GDP per capita",
    title = "GDP per capita on Five continents"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


### Transforming

- Transforming: perform some calculations on or summarize your data before producing the plot 

### Use pipes to summarize data

Also, we experiment bar charts here. By default, `geom_bar` [uses](https://www.rdocumentation.org/packages/ggplot2/versions/1.0.1/topics/geom_bar) stat = "bins", which makes the height of each bar equal to the number of cases in each group. If you have a y column, then you should use `stat = "identity"` argument. Alternatively, you can use `geom_col()`.

```{r}
gapminder_formatted <- gapminder %>%
  group_by(continent, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  )
ggplot(data = gapminder_formatted, aes(x = year, y = lifeExp_mean, color = continent)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy on Five continents"
  )
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean, color = country)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  )
```

```{r}
# geom point
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  facet_wrap(~country)
# geom bar
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean)) +
  geom_bar(stat = "identity") +
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  facet_wrap(~country)
# no facet
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = year, y = lifeExp_mean, fill = country)) +
  geom_bar(stat = "identity") + # even if you not stack, still the plot looks messy or you can use geom_col()
  labs(
    x = "Year",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  )
```

```{r}
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = country, y = lifeExp_mean)) +
  geom_boxplot() +
  labs(
    x = "Country",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  coord_flip()
```

```{r}
# without ordering
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = reorder(country, lifeExp_mean), y = lifeExp_mean)) +
  geom_boxplot() +
  labs(
    x = "Country",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  coord_flip()
# reorder
gapminder %>%
  filter(continent == "Europe") %>%
  group_by(country, year) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = reorder(country, -lifeExp_mean), y = lifeExp_mean)) +
  geom_boxplot() +
  labs(
    x = "Country",
    y = "Life expectancy",
    title = "Life expectancy in Europe"
  ) +
  coord_flip()
```

### Plotting text

```{r}
gapminder %>%
  filter(continent == "Asia" | continent == "Americas") %>%
  group_by(continent, country) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = gdp_mean, y = lifeExp_mean)) +
  geom_point() +
  geom_text(aes(label = country)) +
  scale_x_log10() +
  facet_grid(~continent)
```

```{r}
# with label
gapminder %>%
  filter(continent == "Asia" | continent == "Americas") %>%
  group_by(continent, country) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = gdp_mean, y = lifeExp_mean)) +
  geom_point() +
  geom_label(aes(label = country)) +
  scale_x_log10() +
  facet_grid(~continent)
```

```{r}
# no overlaps
gapminder %>%
  filter(continent == "Asia" | continent == "Americas") %>%
  group_by(continent, country) %>%
  summarize(
    gdp_mean = mean(gdpPercap),
    lifeExp_mean = mean(lifeExp)
  ) %>%
  ggplot(aes(x = gdp_mean, y = lifeExp_mean)) +
  geom_point() +
  geom_text_repel(aes(label = country)) + # there's also geom_label_repel
  scale_x_log10() +
  facet_grid(~continent)
```

## Ploting models 

In plotting models, we extensively use David Robinson's [broom package](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) in R. The idea is to transform model outputs (i.e., predictions and estimations) into tidy objects so that we can easily combine, separate, and visualize these elements. 

### Plotting several fits at the same time

```{r}
model_colors <- RColorBrewer::brewer.pal(3, "Set1") # select three qualitatively different colors from a larger palette.
gapminder %>%
  ggplot(aes(x = log(gdpPercap), y = lifeExp)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "lm", aes(color = "OLS", fill = "OLS")) +
  geom_smooth(
    method = "lm", formula = y ~ splines::bs(x, df = 3),
    aes(color = "Cubic Spline", fill = "Cubic Spline")
  ) +
  geom_smooth(method = "loess", aes(color = "LOESS", fill = "LOESS")) +
  theme(legend.position = "top") +
  scale_color_manual(name = "Models", values = model_colors) +
  scale_fill_manual(name = "Models", values = model_colors)
```

### Extracting model outcomes 

```{r}
# regression model
out <- lm(
  formula = lifeExp ~ gdpPercap + pop + continent,
  data = gapminder
)
```

`tidy()` is a method in the `broom` package. It "constructs a dataframe that summarizes the model's statistical findings". As the description states, tidy is a function that can be used for various models. For instance, a tidy can extract following information from a regression model.

- `Term`: a term being estimated 
- `p.value`
- `statistic`: a test statistic used to compute p-value
- `estimate` 
- `conf.low`: the low end of a confidence interval 
- `conf.high`: the high end of a confidence interval
- `df`: degrees of freedom

**Challenge**

Try `glance(out)`, what did you get from these commands? If you're curious, you can try `?glance`.

The followings are to show your degree of confidence.

#### Coefficients

```{r}
# estimates
out_comp <- tidy(out)
p <- out_comp %>%
  ggplot(aes(x = term, y = estimate))
p + geom_point() +
  coord_flip() +
  theme_bw()
```

#### Confidence intervals

```{r}
# plus confidence intervals
out_conf <- tidy(out, conf.int = TRUE)
# plotting coefficients using ggplot2 (pointrange)
out_conf %>%
  ggplot(aes(x = reorder(term, estimate), y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_pointrange() +
  coord_flip() +
  labs(x = "", y = "OLS Estimate") +
  theme_bw()
# another way to do it (errorbar)
out_conf %>%
  ggplot(aes(x = estimate, y = reorder(term, estimate))) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
  labs(y = "", x = "OLS Estimate") +
  theme_bw()
```

You can calculate marginal effects using the `margins` package. For the sake of time, I'm not covering that here.
